# ai-counsel/config.yaml
version: "1.1"

adapters:
  # CLI Adapters
  claude:
    type: cli
    command: "node"
    args: ["C:\\Users\\btf\\AppData\\Roaming\\npm\\node_modules\\@anthropic-ai\\claude-code\\cli.js", "-p", "--model", "{model}", "--settings", "{{\"disableAllHooks\": true}}", "{prompt}"]
    timeout: 300

  codex:
    type: cli
    command: "node"
    args: ["C:\\Users\\btf\\AppData\\Roaming\\npm\\node_modules\\@openai\\codex\\bin\\codex.js", "exec", "--skip-git-repo-check", "--sandbox", "workspace-write", "--model", "{model}", "{prompt}"]
    timeout: 300

  gemini:
    type: cli
    command: "node"
    args: ["C:\\Users\\btf\\AppData\\Roaming\\npm\\node_modules\\@google\\gemini-cli\\dist\\index.js", "--allowed-mcp-server-names", "none", "-m", "{model}", "-p", "{prompt}"]
    timeout: 300

  # HTTP Adapters
  lmstudio:
    type: http
    base_url: "http://127.0.0.1:1234"
    timeout: 300
    max_retries: 3
    # LM Studio local server - OpenAI-compatible API

  nvmdapi:
    type: openai
    base_url: "https://api.loc.nv.md/v1"
    api_key: "${NVMD_API_KEY}"
    timeout: 300
    max_retries: 3
    responses_api_prefixes: ["o1", "o3", "o4", "gpt-5-pro", "gpt-5.2-pro"]  # Reasoning models use Responses API
    # nvmd - OpenAI-compatible API

  nvmdapicli:
    type: openai
    base_url: "https://apicli.loc.nv.md/v1"
    api_key: "${NVMD_API_KEY}"
    timeout: 300
    max_retries: 3
    responses_api_prefixes: []  # Empty = all models use Chat Completions; add prefixes if Responses API supported
    # nvmd-cli - OpenAI-compatible API (Claude, GPT, Gemini, DeepSeek)

  openai:
    type: openai
    base_url: "https://api.openai.com/v1"
    api_key: "${OPENAI_API_KEY}"
    timeout: 300
    max_retries: 3
    responses_api_prefixes: ["o1", "o3", "o4", "gpt-5-pro", "gpt-5.2-pro"]  # Models using Responses API
    # max_output_tokens: 16384  # Optional: limit for Responses API
    # max_completion_tokens: 16384  # Optional: limit for Chat Completions API
    # OpenAI direct API access
    # Reasoning models (o1/o3/o4) and Pro models (gpt-5-pro, gpt-5.2-pro): Use Responses API
    # Other GPT models: Use Chat Completions API
    # Requires API key from https://platform.openai.com/api-keys

defaults:
  mode: "quick"
  rounds: 2
  max_rounds: 5
  timeout_per_round: 300

model_registry:
  claude:
    - id: "opus"
      label: "Claude Opus 4"
      tier: "premium"
      default: true
      enabled: true
    - id: "sonnet"
      label: "Claude Sonnet 4"
      tier: "balanced"
      enabled: true
    - id: "haiku"
      label: "Claude Haiku"
      tier: "speed"
      enabled: true
  codex:
    - id: "gpt-5.2-codex"
      label: "GPT-5.2 Codex"
      tier: "flagship"
      default: true
      enabled: true
    - id: "gpt-5.2"
      label: "GPT-5.2"
      tier: "flagship"
      enabled: true
    - id: "gpt-5.1-codex-max"
      label: "GPT-5.1 Codex Max"
      tier: "premium"
      enabled: true
    - id: "gpt-5.1-codex-mini"
      label: "GPT-5.1 Codex Mini"
      tier: "speed"
      enabled: true
  gemini:
    - id: "gemini-3-pro-preview"
      label: "Gemini 3 Pro Preview"
      tier: "premium"
      default: true
      enabled: true
    - id: "gemini-3-flash-preview"
      label: "Gemini 3 Flash Preview"
      tier: "balanced"
      enabled: true
    - id: "gemini-2.5-pro"
      label: "Gemini 2.5 Pro"
      tier: "premium"
      enabled: true
    - id: "gemini-2.5-flash"
      label: "Gemini 2.5 Flash"
      tier: "balanced"
      enabled: true
    - id: "gemini-2.5-flash-lite"
      label: "Gemini 2.5 Flash Lite"
      tier: "speed"
      enabled: true
  nvmdapi:
    # nvmd: GPT-5.2 (latest)
    - id: "gpt-5.2-xhigh"
      label: "GPT-5.2 (xhigh reasoning)"
      tier: "flagship"
      enabled: true
    - id: "gpt-5.2"
      label: "GPT-5.2"
      tier: "flagship"
      default: true
      enabled: true
    - id: "gpt-5.2-medium"
      label: "GPT-5.2 (medium)"
      tier: "balanced"
      enabled: true
    # GPT-5.1 Codex Max
    - id: "gpt-5.1-codex-max-xhigh"
      label: "GPT-5.1 Codex Max (xhigh)"
      tier: "coding"
      enabled: true
    - id: "gpt-5.1-codex-max"
      label: "GPT-5.1 Codex Max"
      tier: "coding"
      enabled: true
    # Speed
    - id: "gpt-5.1-codex-mini"
      label: "GPT-5.1 Codex Mini"
      tier: "speed"
      enabled: true
    - id: "codex-mini"
      label: "Codex Mini"
      tier: "speed"
      enabled: true

  nvmdapicli:
    # Claude
    - id: "claude-opus-4-5-20251101"
      label: "Claude Opus 4.5"
      tier: "premium"
      default: true
      enabled: true
    - id: "claude-sonnet-4-5-20250929"
      label: "Claude Sonnet 4.5"
      tier: "balanced"
      enabled: true
    - id: "claude-haiku-4-5-20251001"
      label: "Claude Haiku 4.5"
      tier: "speed"
      enabled: true
    # GPT
    - id: "gpt-5.2"
      label: "GPT-5.2"
      tier: "flagship"
      enabled: true
    - id: "gpt-5.2-codex"
      label: "GPT-5.2 Codex"
      tier: "coding"
      enabled: true
    - id: "gpt-5.1-codex-max"
      label: "GPT-5.1 Codex Max"
      tier: "coding"
      enabled: true
    # Gemini
    - id: "gemini-2.5-pro"
      label: "Gemini 2.5 Pro"
      tier: "premium"
      enabled: true
    - id: "gemini-3-pro-preview"
      label: "Gemini 3 Pro Preview"
      tier: "premium"
      enabled: true
    - id: "gemini-2.5-flash"
      label: "Gemini 2.5 Flash"
      tier: "speed"
      enabled: true
    - id: "gemini-3-flash-preview"
      label: "Gemini 3 Flash Preview"
      tier: "speed"
      enabled: true
    # DeepSeek
    - id: "deepseek-reasoner"
      label: "DeepSeek Reasoner"
      tier: "reasoning"
      enabled: true
    - id: "deepseek-chat"
      label: "DeepSeek Chat"
      tier: "balanced"
      enabled: true

  lmstudio:
    # Large models (70B+)
    - id: "openai/gpt-oss-120b"
      label: "GPT-OSS 120B"
      tier: "flagship"
      enabled: true
    - id: "nousresearch/hermes-4-70b"
      label: "Hermes 4 70B"
      tier: "premium"
      enabled: true
    # Coding models (30B)
    - id: "qwen3-coder-30b-a3b-instruct-1m"
      label: "Qwen3 Coder 30B (1M ctx)"
      tier: "coding"
      enabled: true
    - id: "qwen2.5-coder-32b-instruct"
      label: "Qwen 2.5 Coder 32B"
      tier: "coding"
      enabled: true
    - id: "arch-agent-32b-i1"
      label: "Arch Agent 32B"
      tier: "agent"
      enabled: true
    # Medium models (20B)
    - id: "openai/gpt-oss-20b"
      label: "GPT-OSS 20B"
      tier: "balanced"
      enabled: true
    - id: "mistralai/devstral-small-2507"
      label: "Devstral Small"
      tier: "coding"
      enabled: true
    # Small models (8B)
    - id: "qwen/qwen3-8b"
      label: "Qwen3 8B"
      tier: "speed"
      default: true
      enabled: true
    - id: "deepseek-coder-v2-lite-instruct"
      label: "DeepSeek Coder v2 Lite"
      tier: "speed"
      enabled: true
    # Vision models
    - id: "qwen/qwen3-vl-30b"
      label: "Qwen3 VL 30B (vision)"
      tier: "vision"
      enabled: true
    - id: "qwen/qwen3-vl-8b"
      label: "Qwen3 VL 8B (vision)"
      tier: "vision"
      enabled: true

  openai:
    # ===== Reasoning Models (Responses API) =====
    - id: "o3-pro"
      label: "o3 Pro"
      tier: "premium"
      default: true
      enabled: true
    - id: "o3"
      label: "o3"
      tier: "reasoning"
      enabled: true
    - id: "o1-pro"
      label: "o1 Pro"
      tier: "reasoning"
      enabled: true
    - id: "o1"
      label: "o1"
      tier: "reasoning"
      enabled: true
    - id: "o4-mini"
      label: "o4 Mini"
      tier: "speed"
      enabled: true
    - id: "o3-mini"
      label: "o3 Mini"
      tier: "speed"
      enabled: true
    # ===== GPT Models (Chat Completions API) =====
    - id: "gpt-5.2-pro"
      label: "GPT-5.2 Pro"
      tier: "flagship"
      enabled: true
    - id: "gpt-5.2"
      label: "GPT-5.2"
      tier: "premium"
      enabled: true
    - id: "gpt-5"
      label: "GPT-5"
      tier: "balanced"
      enabled: true
    - id: "gpt-5-pro"
      label: "GPT-5 Pro"
      tier: "flagship"
      enabled: true
    - id: "gpt-4.1"
      label: "GPT-4.1"
      tier: "balanced"
      enabled: true
    - id: "gpt-4o"
      label: "GPT-4o"
      tier: "general"
      enabled: true
    - id: "gpt-4o-mini"
      label: "GPT-4o Mini"
      tier: "speed"
      enabled: true

storage:
  transcripts_dir: "transcripts"
  format: "markdown"
  auto_export: true

mcp:
  max_rounds_in_response: 3
  response_timeout: 300  # 5 min - enough for reasoning models

deliberation:
  convergence_detection:
    enabled: true
    semantic_similarity_threshold: 0.85
    divergence_threshold: 0.40
    min_rounds_before_check: 1
    consecutive_stable_rounds: 2
    stance_stability_threshold: 0.80
    response_length_drop_threshold: 0.40

  early_stopping:
    enabled: true
    threshold: 0.66
    respect_min_rounds: true

  convergence_threshold: 0.8
  enable_convergence_detection: true

  file_tree:
    enabled: true
    max_depth: 2
    max_files: 50

  tool_security:
    exclude_patterns:
      - "transcripts/"
      - "transcripts/**"
      - ".git/"
      - ".git/**"
      - "node_modules/"
      - "node_modules/**"
      - ".venv/"
      - "venv/"
      - "__pycache__/"
    max_file_size_bytes: 1048576

  vote_retry:
    enabled: true
    max_retries: 1
    min_response_length: 100

decision_graph:
  enabled: true
  db_path: "decision_graph.db"
  context_token_budget: 1000
  tier_boundaries:
    strong: 0.75
    moderate: 0.60
  query_window: 1000
  query_cache_size: 200
  embedding_cache_size: 500
  query_ttl: 300
  adaptive_k_small_threshold: 100
  adaptive_k_medium_threshold: 1000
  adaptive_k_small: 5
  adaptive_k_medium: 3
  adaptive_k_large: 2
  noise_floor: 0.40
  max_context_decisions: 3
  compute_similarities: true
